{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ Extracting Text from Scientific Papers with Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 1. Setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Make sure Python can find your scripts folder\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import the functions\n",
    "from scripts.pdf_reader import extract_full_text, extract_partial_text\n",
    "from scripts.rename_pdfs import rename_pdfs_in_folder\n",
    "from scripts.llm_extractor import extract_title_abstract_with_llm\n",
    "from scripts.config_loader import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Load Configuration and Define Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration with a specific profile\n",
    "# Options: 'high_quality' or 'fast_processing' or None for default\n",
    "# ‚¨áÔ∏è Decide which profile to use\n",
    "config = load_config('fast_processing')  # Change this to use different profiles\n",
    "\n",
    "# Print out some key configuration settings\n",
    "print(\"üîç Processing Configuration:\")\n",
    "print(f\"LLM Model: {config.get('llm.model')}\")\n",
    "print(f\"Page Limit for Metadata: {config.get('pdf.extraction.page_limit_for_metadata')}\")\n",
    "print(f\"Extract Full Text: {config.get('pdf.extraction.full_text')}\\n\")\n",
    "\n",
    "# Define batch\n",
    "# ‚¨áÔ∏è Decide which batch to use\n",
    "batch_name = \"third_batch\"\n",
    "\n",
    "# Define folder paths using the configuration \n",
    "pdf_folder = os.path.join(config.get(\"paths.data_dir\"), batch_name)\n",
    "output_file = os.path.join(config.get(\"paths.output_dir\"), f\"{batch_name}.csv\")\n",
    "\n",
    "print(f\"üìÇ PDF Folder: {pdf_folder}\")\n",
    "print(f\"üìÑ Output File: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üñãÔ∏è Rename the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename PDFs using the configuration and get original filename mapping\n",
    "renamed_files, original_filenames_map = rename_pdfs_in_folder(pdf_folder)\n",
    "print(f\"üîÑ Renamed {len(renamed_files)} files\")\n",
    "\n",
    "# Show sample of original to new filename mapping\n",
    "print(\"\\nüìã Sample of original filenames:\")\n",
    "for i, (new_name, original_name) in enumerate(list(original_filenames_map.items())[:3]):\n",
    "    print(f\"  {new_name} ‚Üê {original_name}\")\n",
    "if len(original_filenames_map) > 3:\n",
    "    print(f\"  ... and {len(original_filenames_map) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Extraction on a Single PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single PDF\n",
    "if renamed_files:\n",
    "    single_pdf_path = renamed_files[0]  # Use the first PDF\n",
    "    \n",
    "    # Get page limit from config\n",
    "    page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "    partial_text = extract_partial_text(single_pdf_path, page_limit)\n",
    "    \n",
    "    # Extract title and abstract using the configured model\n",
    "    title, abstract = extract_title_abstract_with_llm(partial_text)\n",
    "    \n",
    "    print(f\"üî¨ Testing extraction on: {os.path.basename(single_pdf_path)}\")\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"\\nAbstract: {abstract[:300]}...\")\n",
    "else:\n",
    "    print(\"‚ùå No PDFs found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìú 2. Extract Text and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "processed_count = 0\n",
    "total_files = len(renamed_files)\n",
    "\n",
    "# Get configuration options\n",
    "extract_full = config.get(\"pdf.extraction.full_text\", True)\n",
    "page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "model = config.get(\"llm.model\")\n",
    "\n",
    "for file_path in renamed_files:\n",
    "    processed_count += 1\n",
    "    filename = os.path.basename(file_path)\n",
    "    original_filename = original_filenames_map.get(filename, \"Unknown\")\n",
    "    \n",
    "    print(f\"Processing {processed_count} of {total_files}: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract text based on configuration\n",
    "        if extract_full:\n",
    "            full_text = extract_full_text(file_path)  # entire PDF text\n",
    "        else:\n",
    "            full_text = \"\"  # Skip full text extraction if disabled in config\n",
    "            \n",
    "        partial_text = extract_partial_text(file_path, page_limit)\n",
    "\n",
    "        # Extract title and abstract\n",
    "        title, abstract = extract_title_abstract_with_llm(partial_text, model)\n",
    "\n",
    "        # Create record with dynamic fields based on config\n",
    "        record = {\n",
    "            \"document_id\": filename,\n",
    "            \"original_filename\": original_filename,\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract\n",
    "        }\n",
    "        \n",
    "        # Only include raw_text if full text extraction is enabled\n",
    "        if extract_full:\n",
    "            record[\"raw_text\"] = full_text\n",
    "            \n",
    "        records.append(record)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        # Add error record\n",
    "        records.append({\n",
    "            \"document_id\": filename,\n",
    "            \"original_filename\": original_filename,\n",
    "            \"title\": \"ERROR: Processing failed\",\n",
    "            \"abstract\": f\"Error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"\\n‚úÖ Processed {len(records)} papers successfully\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 3. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output format from config\n",
    "output_format = config.get(\"output.format\", \"csv\")\n",
    "\n",
    "if output_format == \"csv\":\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"üíæ Saved CSV to: {output_file}\")\n",
    "elif output_format == \"json\":\n",
    "    json_file = output_file.replace(\".csv\", \".json\")\n",
    "    df.to_json(json_file, orient=\"records\", indent=2)\n",
    "    print(f\"üíæ Saved JSON to: {json_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Unsupported output format: {output_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display simple statistics about the extraction\n",
    "print(f\"Total papers processed: {len(df)}\")\n",
    "\n",
    "# Use raw strings (r prefix) for regex patterns to avoid escape issues\n",
    "print(f\"Papers with title extracted: {df['title'].count() - df['title'].str.contains(r'ERROR|I dont know').sum()}\")\n",
    "print(f\"Papers with abstract extracted: {df['abstract'].count() - df['abstract'].str.contains(r'ERROR|I dont know').sum()}\")\n",
    "\n",
    "# Calculate average lengths\n",
    "avg_title_length = df['title'].str.len().mean()\n",
    "avg_abstract_length = df['abstract'].str.len().mean()\n",
    "print(f\"Average title length: {avg_title_length:.1f} characters\")\n",
    "print(f\"Average abstract length: {avg_abstract_length:.1f} characters\")\n",
    "\n",
    "# Show original filename mapping\n",
    "print(\"\\nüîç Sample with original filenames:\")\n",
    "display(df[['document_id', 'original_filename', 'title']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
