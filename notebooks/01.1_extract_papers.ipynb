{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ Extracting Text from Scientific Papers with Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Make sure Python can find your scripts folder\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import the functions\n",
    "from scripts.pdf_reader import extract_full_text, extract_partial_text\n",
    "from scripts.rename_pdfs import rename_pdfs_in_folder\n",
    "from scripts.llm_extractor import extract_title_abstract_with_llm\n",
    "from scripts.config_loader import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Load Configuration and Define Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing Configuration:\n",
      "LLM Model: gpt-3.5-turbo\n",
      "Page Limit for Metadata: 2\n",
      "Extract Full Text: True\n",
      "\n",
      "üìÇ PDF Folder: ../data/batches/third_batch\n",
      "üìÑ Output File: ../outputs/third_batch.csv\n"
     ]
    }
   ],
   "source": [
    "# Load configuration with a specific profile\n",
    "# Options: 'high_quality' or 'fast_processing' or None for default\n",
    "# ‚¨áÔ∏è Decide which profile to use\n",
    "config = load_config('fast_processing')  # Change this to use different profiles\n",
    "\n",
    "# Print out some key configuration settings\n",
    "print(\"üîç Processing Configuration:\")\n",
    "print(f\"LLM Model: {config.get('llm.model')}\")\n",
    "print(f\"Page Limit for Metadata: {config.get('pdf.extraction.page_limit_for_metadata')}\")\n",
    "print(f\"Extract Full Text: {config.get('pdf.extraction.full_text')}\\n\")\n",
    "\n",
    "# Define batch\n",
    "# ‚¨áÔ∏è Decide which batch to use\n",
    "batch_name = \"third_batch\"\n",
    "\n",
    "# Define folder paths using the configuration \n",
    "pdf_folder = os.path.join(config.get(\"paths.data_dir\"), batch_name)\n",
    "output_file = os.path.join(config.get(\"paths.output_dir\"), f\"{batch_name}.csv\")\n",
    "\n",
    "print(f\"üìÇ PDF Folder: {pdf_folder}\")\n",
    "print(f\"üìÑ Output File: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üñãÔ∏è Rename the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Renamed 3 files\n",
      "\n",
      "üìã Sample of original filenames:\n",
      "  paper_001.pdf ‚Üê Technische Innovation, thereotische Sackgasse?.pdf\n",
      "  paper_002.pdf ‚Üê The Dynamics of Political Incivility on Twitter.pdf\n",
      "  paper_003.pdf ‚Üê text-as-data-the-promise-and-pitfalls-of-automatic-content-analysis-methods-for-political-texts.pdf\n"
     ]
    }
   ],
   "source": [
    "# Rename PDFs using the configuration and get original filename mapping\n",
    "renamed_files, original_filenames_map = rename_pdfs_in_folder(pdf_folder)\n",
    "print(f\"üîÑ Renamed {len(renamed_files)} files\")\n",
    "\n",
    "# Show sample of original to new filename mapping\n",
    "print(\"\\nüìã Sample of original filenames:\")\n",
    "for i, (new_name, original_name) in enumerate(list(original_filenames_map.items())[:3]):\n",
    "    print(f\"  {new_name} ‚Üê {original_name}\")\n",
    "if len(original_filenames_map) > 3:\n",
    "    print(f\"  ... and {len(original_filenames_map) - 3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Extraction on a Single PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Testing extraction on: paper_001.pdf\n",
      "\n",
      "Title: Technische Innovation, theoretische Sackgasse? Chancen und Grenzen der automatisierten Inhaltsanalyse in Lehre und Forschung\n",
      "\n",
      "Abstract: Die automatisierte Inhaltsanalyse wird auch in der Journalismusforschung zunehmend genutzt, um Texte (teil)-automatisiert zu analysieren. Sie hat damit zu einer Methodeninnovation im Fach beigetragen, die jedoch selten kritisch diskutiert wird. Der Beitrag gibt einen √úberblick √ºber Chancen und Grenz...\n"
     ]
    }
   ],
   "source": [
    "# Test on a single PDF\n",
    "if renamed_files:\n",
    "    single_pdf_path = renamed_files[0]  # Use the first PDF\n",
    "    \n",
    "    # Get page limit from config\n",
    "    page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "    partial_text = extract_partial_text(single_pdf_path, page_limit)\n",
    "    \n",
    "    # Extract title and abstract using the configured model\n",
    "    title, abstract = extract_title_abstract_with_llm(partial_text)\n",
    "    \n",
    "    print(f\"üî¨ Testing extraction on: {os.path.basename(single_pdf_path)}\")\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"\\nAbstract: {abstract[:300]}...\")\n",
    "else:\n",
    "    print(\"‚ùå No PDFs found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìú 2. Extract Text and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 3: paper_001.pdf\n",
      "Processing 2 of 3: paper_002.pdf\n",
      "Processing 3 of 3: paper_003.pdf\n",
      "\n",
      "‚úÖ Processed 3 papers successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>original_filename</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper_001.pdf</td>\n",
       "      <td>Technische Innovation, thereotische Sackgasse?...</td>\n",
       "      <td>Technische Innovation, theoretische Sackgasse?...</td>\n",
       "      <td>Die automatisierte Inhaltsanalyse wird auch in...</td>\n",
       "      <td>www.ssoar.info\\nTechnische Innovation, theoret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper_002.pdf</td>\n",
       "      <td>The Dynamics of Political Incivility on Twitte...</td>\n",
       "      <td>The Dynamics of Political Incivility</td>\n",
       "      <td>Online incivility and harassment in political ...</td>\n",
       "      <td>919447\\nresearch-article20202020 SGOXXX10.1177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper_003.pdf</td>\n",
       "      <td>text-as-data-the-promise-and-pitfalls-of-autom...</td>\n",
       "      <td>Text as Data: The Promise and Pitfalls of Auto...</td>\n",
       "      <td>Politics and political conflict often occur in...</td>\n",
       "      <td>AdvanceAccesspublicationJanuary22,2013 Politic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                  original_filename  \\\n",
       "0  paper_001.pdf  Technische Innovation, thereotische Sackgasse?...   \n",
       "1  paper_002.pdf  The Dynamics of Political Incivility on Twitte...   \n",
       "2  paper_003.pdf  text-as-data-the-promise-and-pitfalls-of-autom...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Technische Innovation, theoretische Sackgasse?...   \n",
       "1               The Dynamics of Political Incivility   \n",
       "2  Text as Data: The Promise and Pitfalls of Auto...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Die automatisierte Inhaltsanalyse wird auch in...   \n",
       "1  Online incivility and harassment in political ...   \n",
       "2  Politics and political conflict often occur in...   \n",
       "\n",
       "                                            raw_text  \n",
       "0  www.ssoar.info\\nTechnische Innovation, theoret...  \n",
       "1  919447\\nresearch-article20202020 SGOXXX10.1177...  \n",
       "2  AdvanceAccesspublicationJanuary22,2013 Politic...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "processed_count = 0\n",
    "total_files = len(renamed_files)\n",
    "\n",
    "# Get configuration options\n",
    "extract_full = config.get(\"pdf.extraction.full_text\", True)\n",
    "page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "model = config.get(\"llm.model\")\n",
    "\n",
    "for file_path in renamed_files:\n",
    "    processed_count += 1\n",
    "    filename = os.path.basename(file_path)\n",
    "    original_filename = original_filenames_map.get(filename, \"Unknown\")\n",
    "    \n",
    "    print(f\"Processing {processed_count} of {total_files}: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract text based on configuration\n",
    "        if extract_full:\n",
    "            full_text = extract_full_text(file_path)  # entire PDF text\n",
    "        else:\n",
    "            full_text = \"\"  # Skip full text extraction if disabled in config\n",
    "            \n",
    "        partial_text = extract_partial_text(file_path, page_limit)\n",
    "\n",
    "        # Extract title and abstract\n",
    "        title, abstract = extract_title_abstract_with_llm(partial_text, model)\n",
    "\n",
    "        # Create record with dynamic fields based on config\n",
    "        record = {\n",
    "            \"document_id\": filename,\n",
    "            \"original_filename\": original_filename,\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract\n",
    "        }\n",
    "        \n",
    "        # Only include raw_text if full text extraction is enabled\n",
    "        if extract_full:\n",
    "            record[\"raw_text\"] = full_text\n",
    "            \n",
    "        records.append(record)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        # Add error record\n",
    "        records.append({\n",
    "            \"document_id\": filename,\n",
    "            \"original_filename\": original_filename,\n",
    "            \"title\": \"ERROR: Processing failed\",\n",
    "            \"abstract\": f\"Error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"\\n‚úÖ Processed {len(records)} papers successfully\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 3. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved CSV to: ../outputs/third_batch.csv\n"
     ]
    }
   ],
   "source": [
    "# Get output format from config\n",
    "output_format = config.get(\"output.format\", \"csv\")\n",
    "\n",
    "if output_format == \"csv\":\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"üíæ Saved CSV to: {output_file}\")\n",
    "elif output_format == \"json\":\n",
    "    json_file = output_file.replace(\".csv\", \".json\")\n",
    "    df.to_json(json_file, orient=\"records\", indent=2)\n",
    "    print(f\"üíæ Saved JSON to: {json_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Unsupported output format: {output_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers processed: 3\n",
      "Papers with title extracted: 3\n",
      "Papers with abstract extracted: 3\n",
      "Average title length: 85.3 characters\n",
      "Average abstract length: 823.3 characters\n",
      "\n",
      "üîç Sample with original filenames:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>original_filename</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper_001.pdf</td>\n",
       "      <td>Technische Innovation, thereotische Sackgasse?...</td>\n",
       "      <td>Technische Innovation, theoretische Sackgasse?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper_002.pdf</td>\n",
       "      <td>The Dynamics of Political Incivility on Twitte...</td>\n",
       "      <td>The Dynamics of Political Incivility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper_003.pdf</td>\n",
       "      <td>text-as-data-the-promise-and-pitfalls-of-autom...</td>\n",
       "      <td>Text as Data: The Promise and Pitfalls of Auto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                  original_filename  \\\n",
       "0  paper_001.pdf  Technische Innovation, thereotische Sackgasse?...   \n",
       "1  paper_002.pdf  The Dynamics of Political Incivility on Twitte...   \n",
       "2  paper_003.pdf  text-as-data-the-promise-and-pitfalls-of-autom...   \n",
       "\n",
       "                                               title  \n",
       "0  Technische Innovation, theoretische Sackgasse?...  \n",
       "1               The Dynamics of Political Incivility  \n",
       "2  Text as Data: The Promise and Pitfalls of Auto...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display simple statistics about the extraction\n",
    "print(f\"Total papers processed: {len(df)}\")\n",
    "\n",
    "# Use raw strings (r prefix) for regex patterns to avoid escape issues\n",
    "print(f\"Papers with title extracted: {df['title'].count() - df['title'].str.contains(r'ERROR|I dont know').sum()}\")\n",
    "print(f\"Papers with abstract extracted: {df['abstract'].count() - df['abstract'].str.contains(r'ERROR|I dont know').sum()}\")\n",
    "\n",
    "# Calculate average lengths\n",
    "avg_title_length = df['title'].str.len().mean()\n",
    "avg_abstract_length = df['abstract'].str.len().mean()\n",
    "print(f\"Average title length: {avg_title_length:.1f} characters\")\n",
    "print(f\"Average abstract length: {avg_abstract_length:.1f} characters\")\n",
    "\n",
    "# Show original filename mapping\n",
    "print(\"\\nüîç Sample with original filenames:\")\n",
    "display(df[['document_id', 'original_filename', 'title']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
