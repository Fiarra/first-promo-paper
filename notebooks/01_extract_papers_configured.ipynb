{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìÑ Extracting Text from Scientific Papers with Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 1. Setup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Make sure Python can find your scripts folder\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import the functions\n",
    "from scripts.pdf_reader import extract_full_text, extract_partial_text\n",
    "from scripts.rename_pdfs import rename_pdfs_in_folder\n",
    "from scripts.llm_extractor import extract_title_abstract_with_llm\n",
    "from scripts.config_loader import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Load Configuration and Define Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing Configuration:\n",
      "LLM Model: gpt-4o\n",
      "Page Limit for Metadata: 5\n",
      "Extract Full Text: True\n",
      "\n",
      "üìÇ PDF Folder: ../data/batches/second_batch\n",
      "üìÑ Output File: ../outputs/second_batch.csv\n"
     ]
    }
   ],
   "source": [
    "# Load configuration with a specific profile\n",
    "# Options: 'high_quality' or 'fast_processing' or None for default\n",
    "# ‚¨áÔ∏è Decide which profile to use\n",
    "config = load_config('high_quality')  # Change this to use different profiles\n",
    "\n",
    "# Print out some key configuration settings\n",
    "print(\"üîç Processing Configuration:\")\n",
    "print(f\"LLM Model: {config.get('llm.model')}\")\n",
    "print(f\"Page Limit for Metadata: {config.get('pdf.extraction.page_limit_for_metadata')}\")\n",
    "print(f\"Extract Full Text: {config.get('pdf.extraction.full_text')}\\n\")\n",
    "\n",
    "# Define batch\n",
    "# ‚¨áÔ∏è Decide which batch to use\n",
    "batch_name = \"second_batch\"\n",
    "\n",
    "# Define folder paths using the configuration \n",
    "pdf_folder = os.path.join(config.get(\"paths.data_dir\"), batch_name)\n",
    "output_file = os.path.join(config.get(\"paths.output_dir\"), f\"{batch_name}.csv\")\n",
    "\n",
    "print(f\"üìÇ PDF Folder: {pdf_folder}\")\n",
    "print(f\"üìÑ Output File: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üñãÔ∏è Rename the PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Renamed 11 files\n"
     ]
    }
   ],
   "source": [
    "# Rename PDFs using the configuration\n",
    "renamed_files = rename_pdfs_in_folder(pdf_folder)\n",
    "print(f\"üîÑ Renamed {len(renamed_files)} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Extraction on a Single PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Testing extraction on: paper_001.pdf\n",
      "\n",
      "Title: Implementation and evaluation of an additional GPT-4-based reviewer in PRISMA-based medical systematic literature reviews\n",
      "\n",
      "Abstract: Background: PRISMA-based literature reviews require meticulous scrutiny of extensive textual data by multiple reviewers, which is associated with considerable human effort. Objective: To evaluate feasibility and reliability of using GPT-4 API as a complementary reviewer in systematic literature revi...\n"
     ]
    }
   ],
   "source": [
    "# Test on a single PDF\n",
    "if renamed_files:\n",
    "    single_pdf_path = renamed_files[0]  # Use the first PDF\n",
    "    \n",
    "    # Get page limit from config\n",
    "    page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "    partial_text = extract_partial_text(single_pdf_path, page_limit)\n",
    "    \n",
    "    # Extract title and abstract using the configured model\n",
    "    title, abstract = extract_title_abstract_with_llm(partial_text)\n",
    "    \n",
    "    print(f\"üî¨ Testing extraction on: {os.path.basename(single_pdf_path)}\")\n",
    "    print(f\"\\nTitle: {title}\")\n",
    "    print(f\"\\nAbstract: {abstract[:300]}...\")\n",
    "else:\n",
    "    print(\"‚ùå No PDFs found to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìú 2. Extract Text and Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 of 11: paper_001.pdf\n",
      "Processing 2 of 11: paper_002.pdf\n",
      "Processing 3 of 11: paper_003.pdf\n",
      "Processing 4 of 11: paper_004.pdf\n",
      "Processing 5 of 11: paper_005.pdf\n",
      "Processing 6 of 11: paper_006.pdf\n",
      "Processing 7 of 11: paper_007.pdf\n",
      "Processing 8 of 11: paper_008.pdf\n",
      "Processing 9 of 11: paper_009.pdf\n",
      "Processing 10 of 11: paper_010.pdf\n",
      "Processing 11 of 11: paper_011.pdf\n",
      "\n",
      "‚úÖ Processed 11 papers successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper_001.pdf</td>\n",
       "      <td>Implementation and evaluation of an additional...</td>\n",
       "      <td>Background: PRISMA-based literature reviews re...</td>\n",
       "      <td>InternationalJournalofMedicalInformatics189(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper_002.pdf</td>\n",
       "      <td>Automating Systematic Literature Reviews with ...</td>\n",
       "      <td>Objectives: An SLR is presented focusing on te...</td>\n",
       "      <td>Preprint of: Sundaram, G. and Berleant, D., Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paper_003.pdf</td>\n",
       "      <td>Cutting Through the Clutter: The Potential of ...</td>\n",
       "      <td>In academic research, systematic literature re...</td>\n",
       "      <td>Cutting Through the Clutter: The Potential of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paper_004.pdf</td>\n",
       "      <td>Can large language models replace humans in sy...</td>\n",
       "      <td>Systematic reviews are vital for guiding pract...</td>\n",
       "      <td>Received:10October2023 Revised:6February2024 A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper_005.pdf</td>\n",
       "      <td>Title and abstract screening for literature re...</td>\n",
       "      <td>Background Systematically screening published ...</td>\n",
       "      <td>Dennst√§dt et al. Systematic Reviews (2024) 13:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     document_id                                              title  \\\n",
       "0  paper_001.pdf  Implementation and evaluation of an additional...   \n",
       "1  paper_002.pdf  Automating Systematic Literature Reviews with ...   \n",
       "2  paper_003.pdf  Cutting Through the Clutter: The Potential of ...   \n",
       "3  paper_004.pdf  Can large language models replace humans in sy...   \n",
       "4  paper_005.pdf  Title and abstract screening for literature re...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Background: PRISMA-based literature reviews re...   \n",
       "1  Objectives: An SLR is presented focusing on te...   \n",
       "2  In academic research, systematic literature re...   \n",
       "3  Systematic reviews are vital for guiding pract...   \n",
       "4  Background Systematically screening published ...   \n",
       "\n",
       "                                            raw_text  \n",
       "0  InternationalJournalofMedicalInformatics189(20...  \n",
       "1  Preprint of: Sundaram, G. and Berleant, D., Au...  \n",
       "2  Cutting Through the Clutter: The Potential of ...  \n",
       "3  Received:10October2023 Revised:6February2024 A...  \n",
       "4  Dennst√§dt et al. Systematic Reviews (2024) 13:...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "processed_count = 0\n",
    "total_files = len(renamed_files)\n",
    "\n",
    "# Get configuration options\n",
    "extract_full = config.get(\"pdf.extraction.full_text\", True)\n",
    "page_limit = config.get(\"pdf.extraction.page_limit_for_metadata\")\n",
    "model = config.get(\"llm.model\")\n",
    "\n",
    "for file_path in renamed_files:\n",
    "    processed_count += 1\n",
    "    print(f\"Processing {processed_count} of {total_files}: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract text based on configuration\n",
    "        if extract_full:\n",
    "            full_text = extract_full_text(file_path)  # entire PDF text\n",
    "        else:\n",
    "            full_text = \"\"  # Skip full text extraction if disabled in config\n",
    "            \n",
    "        partial_text = extract_partial_text(file_path, page_limit)\n",
    "\n",
    "        # Extract title and abstract\n",
    "        title, abstract = extract_title_abstract_with_llm(partial_text, model)\n",
    "\n",
    "        # Create record with dynamic fields based on config\n",
    "        record = {\n",
    "            \"document_id\": os.path.basename(file_path),\n",
    "            \"title\": title,\n",
    "            \"abstract\": abstract\n",
    "        }\n",
    "        \n",
    "        # Only include raw_text if full text extraction is enabled\n",
    "        if extract_full:\n",
    "            record[\"raw_text\"] = full_text\n",
    "            \n",
    "        records.append(record)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        # Add error record\n",
    "        records.append({\n",
    "            \"document_id\": os.path.basename(file_path),\n",
    "            \"title\": \"ERROR: Processing failed\",\n",
    "            \"abstract\": f\"Error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(f\"\\n‚úÖ Processed {len(records)} papers successfully\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 3. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved CSV to: ../outputs/second_batch.csv\n"
     ]
    }
   ],
   "source": [
    "# Get output format from config\n",
    "output_format = config.get(\"output.format\", \"csv\")\n",
    "\n",
    "if output_format == \"csv\":\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"üíæ Saved CSV to: {output_file}\")\n",
    "elif output_format == \"json\":\n",
    "    json_file = output_file.replace(\".csv\", \".json\")\n",
    "    df.to_json(json_file, orient=\"records\", indent=2)\n",
    "    print(f\"üíæ Saved JSON to: {json_file}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Unsupported output format: {output_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (2702739586.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Papers with title extracted: {df['title'].count() - df['title'].str.contains('ERROR|I don\\\\'t know').sum()}\")\u001b[0m\n\u001b[0m                                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "# Display simple statistics about the extraction\n",
    "print(f\"Total papers processed: {len(df)}\")\n",
    "print(f\"Papers with title extracted: {df['title'].count() - df['title'].str.contains('ERROR|I don\\\\'t know').sum()}\")\n",
    "print(f\"Papers with abstract extracted: {df['abstract'].count() - df['abstract'].str.contains('ERROR|I don\\\\'t know').sum()}\")\n",
    "\n",
    "# Calculate average lengths\n",
    "avg_title_length = df['title'].str.len().mean()\n",
    "avg_abstract_length = df['abstract'].str.len().mean()\n",
    "print(f\"Average title length: {avg_title_length:.1f} characters\")\n",
    "print(f\"Average abstract length: {avg_abstract_length:.1f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
